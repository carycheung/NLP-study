{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 04 Deep Learning and Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nueral Network and Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract netural network graph node.\n",
    "\n",
    "class Node(object):\n",
    "    \"\"\"\n",
    "    Node\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs=[]):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "\n",
    "        for n in self.inputs:\n",
    "            n.outputs.append(self) # set 'self' node as inbound_node's outbound_nodes\n",
    "\n",
    "        self.value = None\n",
    "\n",
    "        # keys are the inputs to this node and their values are partials of this node\n",
    "        # with respect to that input.\n",
    "        # \\partial{node}{input_i}\n",
    "        self.gradients = {}\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "        Compute the output value based on 'inbound_nodes' and store the results\n",
    "        in self.value\n",
    "        \"\"\"\n",
    "        raise  NotImplemented()\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Back propagation.\n",
    "        \"\"\"\n",
    "        raise NotImplemented()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input(Node):\n",
    "    \"\"\"\n",
    "    Input Node.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        Node.__init__(self)\n",
    "\n",
    "    def forward(self, value=None):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "\n",
    "        Only input node is the node where the value may be passed as an argument to forward().\n",
    "        All other node implementation should get value of the previous node from self.inbound[0].value\n",
    "        \"\"\"\n",
    "        if value is not None:\n",
    "            self.value = value\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Back propagation.\n",
    "        \"\"\"\n",
    "        self.gradients = {self: 0}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self] = grad_cost * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(Node):\n",
    "    \"\"\"\n",
    "    Add operation.\n",
    "    \"\"\"\n",
    "    def __init__(self, *nodes):\n",
    "        Node.__init__(self, nodes)\n",
    "\n",
    "    def forward(self):\n",
    "        self.value = sum(map(lambda n: n.value, self.inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = w*x + b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Node):\n",
    "    \"\"\"\n",
    "    Linear Op.\n",
    "    \"\"\"\n",
    "    def __init__(self, nodes, weights, bias):\n",
    "        Node.__init__(self, [nodes, weights, bias])\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "        y = w*x + b\n",
    "        \"\"\"\n",
    "        inputs = self.inputs[0].value\n",
    "        weights = self.inputs[1].value\n",
    "        bias = self.inputs[2].value\n",
    "\n",
    "        self.value = np.dot(inputs, weights) + bias\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Backword propagation.\n",
    "        \"\"\"\n",
    "        # initialize a partial for each inbound_nodes.\n",
    "        self.gradients = { n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "\n",
    "            self.gradients[self.inputs[0]] = np.dot(grad_cost, self.inputs[1].value.T)\n",
    "            self.gradients[self.inputs[1]] = np.dot(self.inputs[0].value.T, grad_cost)\n",
    "            self.gradients[self.inputs[2]] = np.sum(grad_cost, axis=0, keepdims=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_sigmoid(x):\n",
    "    \"\"\"\n",
    "    sigmoid operation.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sigma'(x) = \\sigma * (1 - \\sigma)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_sigmoid_derivative(x):\n",
    "    \"\"\"\n",
    "    sigmoid derivative.\n",
    "    \"\"\"\n",
    "    return op_sigmoid(x) * (1 - op_sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Node):\n",
    "    \"\"\"\n",
    "    Sigmoid Op.\n",
    "    \"\"\"\n",
    "    def __init__(self, node):\n",
    "        Node.__init__(self, [node])\n",
    "\n",
    "    def forward(self,):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "        \"\"\"\n",
    "        self.x = self.inputs[0].value\n",
    "        self.value = op_sigmoid(self.x)\n",
    "\n",
    "    def backward(self,):\n",
    "        \"\"\"\n",
    "        Back propagation.\n",
    "        \"\"\"\n",
    "        self.gradients = { n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self.inputs[0]] = grad_cost * op_sigmoid_derivative(self.x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L(y, \\hat{y}) = \\frac{1}{N}\\sum{(y - \\hat{y})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial L}{\\partial{y}} = \\frac{2}{N} \\sum{(y - \\hat{y})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial L}{\\partial{\\hat{y}}} = -\\frac{2}{N} \\sum{(y - \\hat{y})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Node):\n",
    "    \"\"\"\n",
    "    Mean Square Error.\n",
    "    \"\"\"\n",
    "    def __init__(self, y, y_hat):\n",
    "        Node.__init__(self, [y, y_hat])\n",
    "\n",
    "    def forward(self):\n",
    "        y = self.inputs[0].value.reshape(-1, 1)\n",
    "        y_hat = self.inputs[1].value.reshape(-1, 1)\n",
    "        assert y.shape == y_hat.shape\n",
    "\n",
    "        self.m = self.inputs[0].value.shape[0]\n",
    "        self.diff = y - y_hat\n",
    "\n",
    "        self.value = np.mean(self.diff ** 2)\n",
    "\n",
    "    def backward(self):\n",
    "        self.gradients[self.inputs[0]] = (2 / self.m) * self.diff\n",
    "        self.gradients[self.inputs[1]] = (-2 / self.m) * self.diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(output_node, graph):\n",
    "    \"\"\"\n",
    "    Execute all the forward method of sorted nodes.\n",
    "    \"\"\"\n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "\n",
    "    for n in graph[::-1]:\n",
    "        n.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort generic nodes in topological order using Kahn's Algorithm.\n",
    "    `feed_dict`: A dictionary where the key is a `Input` node and the value is the respective value feed to that node.\n",
    "    Returns a list of sorted nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outputs:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "            ## if n is Input Node, set n'value as \n",
    "            ## feed_dict[n]\n",
    "            ## else, n's value is caculate as its\n",
    "            ## inbounds\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outputs:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_update(trainables, learning_rate=1e-3):\n",
    "    \"\"\"\n",
    "    Stochastic Grandient Descent.\n",
    "    \"\"\"\n",
    "    for t in trainables:\n",
    "        t.value += -1 * learning_rate * t.gradients[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle, resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_dataset = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_dataset.data.shape, boston_dataset.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle, resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 436.427\n",
      "Epoch: 100, Loss: 19.352\n",
      "Epoch: 200, Loss: 13.403\n",
      "Epoch: 300, Loss: 11.375\n",
      "Epoch: 400, Loss: 9.816\n",
      "Epoch: 500, Loss: 8.103\n",
      "Epoch: 600, Loss: 8.236\n",
      "Epoch: 700, Loss: 7.115\n",
      "Epoch: 800, Loss: 7.631\n",
      "Epoch: 900, Loss: 6.565\n",
      "Epoch: 1000, Loss: 7.251\n",
      "Epoch: 1100, Loss: 6.546\n",
      "Epoch: 1200, Loss: 6.384\n",
      "Epoch: 1300, Loss: 5.656\n",
      "Epoch: 1400, Loss: 5.789\n",
      "Epoch: 1500, Loss: 5.381\n",
      "Epoch: 1600, Loss: 5.192\n",
      "Epoch: 1700, Loss: 5.553\n",
      "Epoch: 1800, Loss: 4.946\n",
      "Epoch: 1900, Loss: 5.355\n"
     ]
    }
   ],
   "source": [
    "dataset = load_boston()\n",
    "\n",
    "X_ = dataset['data']\n",
    "Y_ = dataset['target']\n",
    "\n",
    "# normalize data\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0)\n",
    "\n",
    "n_features = X_.shape[1] # feature number\n",
    "n_hidden = 10  # hidden layer node number\n",
    "\n",
    "\n",
    "# Initialize W1, b1, W2, b2 paramerters\n",
    "W1_ = np.random.randn(n_features, n_hidden)\n",
    "b1_ = np.zeros(n_hidden)\n",
    "W2_ = np.random.randn(n_hidden, 1)\n",
    "b2_ = np.zeros(1)\n",
    "\n",
    "# Neural Network\n",
    "X, Y = Input(), Input()\n",
    "W1, b1 = Input(), Input()\n",
    "W2, b2 = Input(), Input()\n",
    "\n",
    "l1 = Linear(X, W1, b1)\n",
    "s1 = Sigmoid(l1)\n",
    "l2 = Linear(s1, W2, b2)\n",
    "cost = MSE(Y, l2)\n",
    "\n",
    "feed_dict = {\n",
    "    X: X_,\n",
    "    Y: Y_,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_\n",
    "}\n",
    "\n",
    "epochs = 2000\n",
    "\n",
    "m = X_.shape[0]\n",
    "batch_size = 16\n",
    "steps_per_epoch = m // batch_size\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "trainables = [W1, b1, W2, b2]\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        X_batch, Y_batch = resample(X_, Y_, n_samples=batch_size)\n",
    "        \n",
    "        X.value = X_batch\n",
    "        Y.value = Y_batch\n",
    "\n",
    "        # forward and backward\n",
    "        forward_and_backward(None, graph)\n",
    "\n",
    "        # sgd\n",
    "        sgd_update(trainables)\n",
    "\n",
    "        loss += graph[-1].value\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\"Epoch: {}, Loss: {:.3f}\".format(i, loss/steps_per_epoch))\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24cd230bac8>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-fff9860591be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_epsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcast_to_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfdev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intput:`13` -> Layer1:`40` -> Layer2:`10` -> output: `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=40, activation='sigmoid', input_dim=13))\n",
    "model.add(Dense(units=10, activation='sigmoid', input_dim=40))\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='sgd', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_, Y_, epochs=1000, batch_size=32, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
